[{"title":"Hello World","date":"2016-12-09T09:24:13.000Z","path":"2016/12/09/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]},{"title":"WebMagic(爬虫)","date":"2016-12-09T09:24:13.000Z","path":"2016/12/09/spider/","text":"爬虫文档爬虫核心1. url管理器（Scheduler） 负责待爬页面的link管理 新抓取的link link去重复 2. 下载器（Downloader） 负责从网页上下载页面 使用Apache HttpClient 作为下载工具 由于是访问网页，可能会出现超时返回错误等异常，需要异常处理 3. 解析器（PageProcessor） 负责解析页面，抽取需要的数据信息，发现新link 使用jsoup作为解析html的工具 每个PageProcessor都需要开发者自己定制 4. 结果处理器（Pipeline和HandleResult） Pipeline负责抽取结果的处理 可以把结果做包括计算、持久化到文件、数据库等处理 由于绝大部分真正需要的数据都是不同的页面组合，所以我加了一个处理结果的步骤HandleResult，该步骤在所有爬虫任务结束后执行，需要开发者自己定制 5. 监控","tags":[]}]